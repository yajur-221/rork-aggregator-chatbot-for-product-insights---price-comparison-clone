#!/usr/bin/env python3
"""
Fixed Price Scraper Backend for Railway with Root Route
"""

import os
import requests
from bs4 import BeautifulSoup
import re
import json
import time
from flask import Flask, request, jsonify
from flask_cors import CORS

# Create Flask app
app = Flask(__name__)
CORS(app)  # Enable CORS for React Native

# ===== HELPER FUNCTIONS =====

def clean_price(price_text):
    """Extract numeric price from text"""
    if not price_text:
        return 0
    price_text = re.sub(r'[^\d.]', '', price_text)
    try:
        return float(price_text)
    except:
        return 0

def get_estimated_price(product_name):
    """Get estimated price based on product type"""
    normalized_query = product_name.lower()
    
    # Grocery items
    if any(item in normalized_query for item in ['apple', 'banana', 'fruit']):
        return 150.0
    if 'milk' in normalized_query:
        return 60.0
    if 'bread' in normalized_query:
        return 40.0
    if 'rice' in normalized_query:
        return 80.0
    
    # Electronics
    if 'iphone' in normalized_query:
        return 65000.0
    if 'samsung' in normalized_query and 'phone' in normalized_query:
        return 25000.0
    if 'laptop' in normalized_query:
        return 45000.0
    if 'headphones' in normalized_query:
        return 3000.0
    
    # Fashion
    if 'shirt' in normalized_query:
        return 800.0
    if 'jeans' in normalized_query:
        return 1500.0
    if 'shoes' in normalized_query:
        return 2500.0
    
    # Default
    return 1000.0

# ===== FLASK ROUTES =====

@app.route('/')
def home():
    """Root endpoint"""
    return jsonify({
        'status': 'active',
        'service': 'Price Scraper Backend',
        'version': '1.0.0',
        'endpoints': {
            'health': '/health',
            'scrape_prices': '/scrape/prices/',
            'query_price': '/query/price/'
        },
        'message': 'üöÄ Price Scraper is running! Use POST /scrape/prices/ with {"product_name": "..."}'
    })

@app.route('/health')
@app.route('/health/')
def health_check():
    """Health check endpoint - works with or without trailing slash"""
    return jsonify({
        'status': 'healthy',
        'timestamp': time.time(),
        'message': 'Price Scraper Backend is running!'
    })

@app.route('/scrape/prices/', methods=['POST'])
@app.route('/scrape/prices', methods=['POST'])
def scrape_prices_endpoint():
    """Main scraping endpoint"""
    try:
        # Get JSON data
        data = request.get_json() or {}
        
        # Check for product_name
        product_name = data.get('product_name', '').strip()
        
        if not product_name:
            return jsonify({
                'success': False,
                'error': 'Missing product_name in request',
                'example': 'Send POST with {"product_name": "iPhone 15"}'
            }), 400
        
        if len(product_name) > 100:
            return jsonify({
                'success': False,
                'error': 'Product name too long (max 100 characters)'
            }), 400
        
        print(f"üì± Scraping request for: {product_name}")
        
        # Try to scrape real prices
        prices = scrape_prices(product_name)
        
        # If no real prices found, use mock data
        if not prices:
            print(f"‚ö†Ô∏è No real prices found, using mock data for: {product_name}")
            base_price = get_estimated_price(product_name)
            prices = generate_mock_prices(product_name, base_price)
        
        # Sort by price
        prices.sort(key=lambda x: x['price'])
        
        return jsonify({
            'success': True,
            'products': prices,
            'product_searched': product_name,
            'total_results': len(prices),
            'cheapest': prices[0] if prices else None,
            'timestamp': time.time()
        })
        
    except Exception as e:
        print(f"‚ùå Error in scrape_prices_endpoint: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/query/price/', methods=['POST'])
@app.route('/query/price', methods=['POST'])
def query_price_endpoint():
    """Natural language price query endpoint"""
    try:
        data = request.get_json() or {}
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({
                'success': False,
                'error': 'Missing query in request'
            }), 400
        
        # Extract product from natural language
        product = extract_product_from_query(query)
        
        if not product:
            return jsonify({
                'success': False,
                'message': "Couldn't understand the product. Try 'iPhone 15' or 'Samsung TV'"
            })
        
        # Use the scrape endpoint logic
        prices = scrape_prices(product)
        if not prices:
            base_price = get_estimated_price(product)
            prices = generate_mock_prices(product, base_price)
        
        prices.sort(key=lambda x: x['price'])
        
        return jsonify({
            'success': True,
            'products': prices,
            'product_searched': product,
            'total_results': len(prices),
            'cheapest': prices[0] if prices else None
        })
        
    except Exception as e:
        print(f"‚ùå Error in query_price: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ===== SCRAPING FUNCTIONS =====

def scrape_prices(product_name):
    """Scrape real prices from e-commerce sites"""
    results = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
    }
    
    # Try Amazon
    try:
        print(f"üîç Scraping Amazon for: {product_name}")
        url = f"https://www.amazon.in/s?k={product_name.replace(' ', '+')}"
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        items = soup.find_all('div', {'data-component-type': 's-search-result'})[:3]
        for item in items:
            try:
                title = item.find('h2').text.strip()[:100] if item.find('h2') else product_name
                price_elem = item.find('span', class_='a-price-whole')
                if price_elem:
                    price = clean_price(price_elem.text)
                    if price > 0:
                        results.append({
                            'price': price,
                            'title': title,
                            'platform': 'Amazon',
                            'url': url
                        })
            except:
                continue
        print(f"‚úÖ Amazon: Found {len([r for r in results if r['platform'] == 'Amazon'])} products")
    except Exception as e:
        print(f"‚ö†Ô∏è Amazon scraping failed: {e}")
    
    # Try Flipkart
    try:
        print(f"üîç Scraping Flipkart for: {product_name}")
        url = f"https://www.flipkart.com/search?q={product_name.replace(' ', '%20')}"
        response = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        price_elements = soup.find_all('div', class_='_30jeq3')[:3]
        for price_elem in price_elements:
            try:
                price = clean_price(price_elem.text)
                if price > 0:
                    results.append({
                        'price': price,
                        'title': f"{product_name} - Flipkart",
                        'platform': 'Flipkart',
                        'url': url
                    })
            except:
                continue
        print(f"‚úÖ Flipkart: Found {len([r for r in results if r['platform'] == 'Flipkart'])} products")
    except Exception as e:
        print(f"‚ö†Ô∏è Flipkart scraping failed: {e}")
    
    return results

def generate_mock_prices(product_name, base_price):
    """Generate realistic mock prices as fallback"""
    return [
        {
            'price': base_price,
            'title': f"{product_name} - Amazon Exclusive",
            'platform': 'Amazon',
            'url': f"https://www.amazon.in/s?k={product_name.replace(' ', '+')}"
        },
        {
            'price': base_price * 0.95,
            'title': f"{product_name} - Flipkart Deal",
            'platform': 'Flipkart',
            'url': f"https://www.flipkart.com/search?q={product_name.replace(' ', '%20')}"
        },
        {
            'price': base_price * 1.05,
            'title': f"{product_name} - Croma Store",
            'platform': 'Croma',
            'url': f"https://www.croma.com/search?q={product_name.replace(' ', '%20')}"
        }
    ]

def extract_product_from_query(query):
    """Extract product name from natural language"""
    query = query.lower()
    
    # Remove common words
    remove_words = ['find', 'search', 'get', 'show', 'price', 'cost', 'cheap', 'cheapest', 
                   'best', 'for', 'of', 'the', 'a', 'an', 'is', 'what', 'whats']
    
    words = query.split()
    product_words = [w for w in words if w not in remove_words]
    
    return ' '.join(product_words).strip() if product_words else None

# ===== MAIN ENTRY POINT =====

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    print(f"""
    üöÄ Price Scraper Backend Starting...
    üìç Port: {port}
    üìã Endpoints:
       GET  / - Service info
       GET  /health - Health check
       POST /scrape/prices/ - Scrape prices
       POST /query/price/ - Natural language queries
    
    Test with: curl http://localhost:{port}/health
    """)
    
    # Run the app
    app.run(host='0.0.0.0', port=port, debug=False)
